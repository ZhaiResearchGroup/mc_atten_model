{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import csv\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_data(in_file, max_example=None, relabeling=True):\n",
    "#     \"\"\"\n",
    "#         load CNN / Daily Mail data from {train | dev | test}.txt\n",
    "#         relabeling: relabel the entities by their first occurence if it is True.\n",
    "#     \"\"\"\n",
    "\n",
    "#     documents = []\n",
    "#     questions = []\n",
    "#     answers = []\n",
    "#     num_examples = 0\n",
    "#     f = open(in_file, 'r')\n",
    "#     while True:\n",
    "#         line = f.readline()\n",
    "#         if not line:\n",
    "#             break\n",
    "#         question = line.strip().lower()\n",
    "#         answer = f.readline().strip()\n",
    "#         document = f.readline().strip().lower()\n",
    "\n",
    "#         if relabeling:\n",
    "#             q_words = question.split(' ')\n",
    "#             d_words = document.split(' ')\n",
    "#             assert answer in d_words\n",
    "\n",
    "#             entity_dict = {}\n",
    "#          = 0\n",
    "#             for word in d_words + q_words:\n",
    "#                 if (word.startswith('@entity')) and (word not in entity_dict):\n",
    "#                     entity_dict[word] = '@entity' + str(entity_id)\n",
    "#                     entity_id += 1\n",
    "\n",
    "#             q_words = [entity_dict[w] if w in entity_dict else w for w in q_words]\n",
    "#             d_words = [entity_dict[w] if w in entity_dict else w for w in d_words]\n",
    "#             answer = entity_dict[answer]\n",
    "\n",
    "#             question = ' '.join(q_words)\n",
    "#             document = ' '.join(d_words)\n",
    "\n",
    "#         questions.append(question)\n",
    "#         answers.append(answer)\n",
    "#         documents.append(document)\n",
    "#         num_examples += 1\n",
    "\n",
    "#         f.readline()\n",
    "#         if (max_example is not None) and (num_examples >= max_example):\n",
    "#             break\n",
    "#     f.close()\n",
    "#     logging.info('#Examples: %d' % len(documents))\n",
    "#     return (documents, questions, answers, entity_dict)\n",
    "\n",
    "# #train_documents, train_questions, train_answers = load_data('cnn/train.txt')\n",
    "# test_documents, test_questions, test_answers, test_entities = load_data('cnn/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i, q in enumerate(test_questions):\n",
    "#     test_questions[i] = q.replace('@placeholder', test_answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it has spewed ash to a depth of about 23½ inches in some places , @entity1 officials say'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_questions[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UNK       = 0\n",
    "delimiter = 1\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name, docs, max_words = None):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"UNK\", 1: \"|||\"}\n",
    "      \n",
    "        \"\"\"\n",
    "            Build a dictionary for the words in `sentences`.\n",
    "            Only the max_words ones are kept and the remaining will be mapped to <UNK>.\n",
    "        \"\"\"\n",
    "        word_count = Counter()\n",
    "        for doc in docs:\n",
    "            word_count[delimiter] += 1\n",
    "            for w in doc.split(' '):\n",
    "                word_count[w] += 1\n",
    "            \n",
    "\n",
    "        ls = word_count.most_common(max_words)\n",
    "        \n",
    "        # leave 0 to UNK\n",
    "        # leave 1 to delimiter |||\n",
    "        self.word2index = {w[0]: index + 2 for (index, w) in enumerate(ls)}\n",
    "        self.index2word = {index + 2: w[0] for (index, w) in enumerate(ls)}\n",
    "        \n",
    "        self.n_words = 2 + len(self.word2index)\n",
    "        \n",
    "    def get_word2index(self, word):\n",
    "        if word in self.word2index:\n",
    "            return self.word2index[word]\n",
    "        else:\n",
    "            print(\"unknown word\")\n",
    "            return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( @entity0 ) as ash from @entity1 \\'s @entity2 spread east into @entity3 , geologists warned of the potential for more activity friday . evacuations in the region involved not only people but animals as well . \" there is more seismic activity ... and we think there will be more activity today , \" @entity4 , a spokesman for @entity1 \\'s @entity5 , told @entity0 . the volcano has already erupted twice this week , spewing ash to a depth of about 23½ inches ( 60 centimeters ) in some places , according to the @entity6 and public safety . new advisories say airborne ash could reach an altitude of 12,000 feet . @entity2 erupted twice in 24 hours , the geological agency said early thursday . the agency said it was evaluating a spectacular nighttime eruption but indicated it was \" stronger than the first one . \" in @entity7 , houses , trees and even sheep were blanketed gray with ash , @entity0 \\'s @entity8 reported . people were removing salmon -- a staple of the local economy -- amid fear of contamination from ash and lava . trucks were used to evacuate farm animals and pets . authorities issued a red alert for the popular tourist towns of @entity9 and @entity10 in the south . people were being evacuated to @entity11 on 22 buses and military trucks , the interior ministry said . officials said that volcanic flows from @entity2 caused rising water levels in the @entity12 . a 12 - mile ( 20 - kilometer ) exclusion zone was established around the crater . military and police forces were helping evacuate more than 4,400 residents , the @entity13 said . an additional 2,000 residents of @entity14 were being evacuated as a preventive measure after river levels rose due to volcanic flows . more evacuations were expected in @entity15 and @entity16 . the first eruption on wednesday set off a bit of a panic in the region . \" at the beginning , it was small , and later , the cloud grew . and later , there was a huge cloud over you and true terror starts , \" a @entity9 resident said . another person said : \" it was impressive to see an enormous mushroom cloud , with the immense force of the volcano , and to see the ashes . at that point , there was a lot of panic , lots of chaos , traffic jams , people going to supermarkets , everyone looking for water , trying to take out money from the @entity17 . \" @entity18 under @entity19 more vast than thought the eruption is a first for many in the region . the last major eruption was 1962 . there was a minor eruption in 1972 . @entity2 also belched out a bit of gas and smoke in 1996 . @entity20 , regional director of the @entity13 , said that officials are concerned there might be a third eruption . \" the situation is relatively calm right now , although people are understandably anxious about what could happen tonight , \" he said .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pytorch dataset / dataloader instead\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CNNDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "        \"\"\"\n",
    "            load CNN / Daily Mail data from {train | dev | test}.txt\n",
    "            relabeling: relabel the entities by their first occurence if it is True.\n",
    "        \"\"\"\n",
    "\n",
    "        self.documents = []\n",
    "        self.questions = []\n",
    "        self.answers = []\n",
    "        self.num_examples = 0\n",
    "        \n",
    "        f = open(path, 'r')\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            question = line.strip().lower()\n",
    "            answer = f.readline().strip()\n",
    "            document = f.readline().strip().lower()\n",
    "\n",
    "            if relabeling:\n",
    "                q_words = question.split(' ')\n",
    "                d_words = document.split(' ')\n",
    "                assert answer in d_words\n",
    "\n",
    "                entity_dict = {}\n",
    "                entity_id = 0\n",
    "                for word in d_words + q_words:\n",
    "                    if (word.startswith('@entity')) and (word not in entity_dict):\n",
    "                        entity_dict[word] = '@entity' + str(entity_id)\n",
    "                        entity_id += 1\n",
    "\n",
    "                q_words = [entity_dict[w] if w in entity_dict else w for w in q_words]\n",
    "                d_words = [entity_dict[w] if w in entity_dict else w for w in d_words]\n",
    "                answer = self.entity_dict[answer]\n",
    "\n",
    "                question = ' '.join(q_words)\n",
    "                document = ' '.join(d_words)\n",
    "\n",
    "            self.questions.append(question)\n",
    "            self.answers.append(answer)\n",
    "            self.documents.append(document)\n",
    "            self.num_examples += 1\n",
    "\n",
    "            f.readline()\n",
    "        f.close()\n",
    "    \n",
    "        # remove @placeholders\n",
    "        for i, q in enumerate(self.questions):\n",
    "            self.questions[i] = q.replace('@placeholder', self.answers[i])\n",
    "        \n",
    "        # create vocab object\n",
    "        self.voc = Voc(\"vocab\", self.documents)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_examples\n",
    "    \n",
    "    def indexes_from_sentence(self, sentence):\n",
    "        return [self.voc.get_word2index(word) for word in sentence.split(' ')]\n",
    "\n",
    "    def variable_from_sentence(self, sentence):\n",
    "        indexes = indexes_from_sentence(self.voc, sentence)\n",
    "        indexes.append(delimiter)\n",
    "        var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "        if USE_CUDA: \n",
    "            var = var.cuda()\n",
    "        return var\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ex_idx = random.randrange(0, len(test_documents))\n",
    "    \n",
    "        ex_doc =  self.documents[ex_idx]\n",
    "        ex_ques = self.questions[ex_idx]\n",
    "        input_var = self.variable_from_sentence(ex_doc)\n",
    "        target_var = self.variable_from_sentence(ex_ques)\n",
    "        \n",
    "        return input_var, target_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# voc = Voc(\"vocab\", test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 2,\n",
       " ',': 3,\n",
       " '.': 4,\n",
       " '\"': 5,\n",
       " 'to': 6,\n",
       " 'and': 7,\n",
       " 'of': 8,\n",
       " 'a': 9,\n",
       " 'in': 10,\n",
       " \"'s\": 11,\n",
       " 'that': 12,\n",
       " '@entity1': 13,\n",
       " 'is': 14,\n",
       " 'for': 15,\n",
       " 'on': 16,\n",
       " 'was': 17,\n",
       " 'it': 18,\n",
       " '@entity2': 19,\n",
       " 'said': 20,\n",
       " 'he': 21,\n",
       " '@entity3': 22,\n",
       " '-': 23,\n",
       " 'with': 24,\n",
       " 'as': 25,\n",
       " '@entity4': 26,\n",
       " 'his': 27,\n",
       " 'from': 28,\n",
       " 'have': 29,\n",
       " 'are': 30,\n",
       " 'but': 31,\n",
       " 'at': 32,\n",
       " '@entity5': 33,\n",
       " 'i': 34,\n",
       " 'be': 35,\n",
       " '--': 36,\n",
       " 'has': 37,\n",
       " 'by': 38,\n",
       " 'we': 39,\n",
       " 'not': 40,\n",
       " 'they': 41,\n",
       " 'this': 42,\n",
       " 'an': 43,\n",
       " '@entity0': 44,\n",
       " '@entity6': 45,\n",
       " 'who': 46,\n",
       " ')': 47,\n",
       " '(': 48,\n",
       " \"n't\": 49,\n",
       " 'were': 50,\n",
       " '@entity7': 51,\n",
       " 'their': 52,\n",
       " 'she': 53,\n",
       " 'her': 54,\n",
       " 'will': 55,\n",
       " 'had': 56,\n",
       " '@entity8': 57,\n",
       " 'been': 58,\n",
       " '@entity9': 59,\n",
       " 'people': 60,\n",
       " 'about': 61,\n",
       " 'one': 62,\n",
       " ':': 63,\n",
       " '@entity10': 64,\n",
       " 'more': 65,\n",
       " 'there': 66,\n",
       " 'you': 67,\n",
       " 'or': 68,\n",
       " 'when': 69,\n",
       " 'after': 70,\n",
       " '@entity11': 71,\n",
       " 'what': 72,\n",
       " '@entity12': 73,\n",
       " 'would': 74,\n",
       " '@entity13': 75,\n",
       " 'out': 76,\n",
       " 'all': 77,\n",
       " 'which': 78,\n",
       " 'its': 79,\n",
       " '@entity14': 80,\n",
       " \"'\": 81,\n",
       " 'also': 82,\n",
       " 'do': 83,\n",
       " 'so': 84,\n",
       " 'up': 85,\n",
       " 'police': 86,\n",
       " 'told': 87,\n",
       " 'can': 88,\n",
       " 1: 89,\n",
       " 'than': 90,\n",
       " '@entity16': 91,\n",
       " 'if': 92,\n",
       " 'some': 93,\n",
       " '@entity15': 94,\n",
       " 'year': 95,\n",
       " 'no': 96,\n",
       " 'into': 97,\n",
       " 'two': 98,\n",
       " 'other': 99,\n",
       " 'time': 100,\n",
       " 'them': 101,\n",
       " 'just': 102,\n",
       " 'did': 103,\n",
       " '@entity17': 104,\n",
       " 'him': 105,\n",
       " '?': 106,\n",
       " 'like': 107,\n",
       " 'could': 108,\n",
       " 'our': 109,\n",
       " 'according': 110,\n",
       " '@entity18': 111,\n",
       " 'over': 112,\n",
       " 'years': 113,\n",
       " 'first': 114,\n",
       " '@entity19': 115,\n",
       " 'many': 116,\n",
       " '@entity20': 117,\n",
       " 'now': 118,\n",
       " 'last': 119,\n",
       " 'says': 120,\n",
       " 'my': 121,\n",
       " 'because': 122,\n",
       " 'where': 123,\n",
       " 'government': 124,\n",
       " 'most': 125,\n",
       " 'president': 126,\n",
       " 'only': 127,\n",
       " 'country': 128,\n",
       " 'before': 129,\n",
       " 'those': 130,\n",
       " 'back': 131,\n",
       " 'how': 132,\n",
       " '@entity21': 133,\n",
       " 'even': 134,\n",
       " 'get': 135,\n",
       " '@entity23': 136,\n",
       " 'then': 137,\n",
       " 'while': 138,\n",
       " 'against': 139,\n",
       " 'family': 140,\n",
       " 'world': 141,\n",
       " '@entity22': 142,\n",
       " 'being': 143,\n",
       " 'still': 144,\n",
       " 'new': 145,\n",
       " 'these': 146,\n",
       " 'life': 147,\n",
       " 'state': 148,\n",
       " 'any': 149,\n",
       " 'made': 150,\n",
       " 'group': 151,\n",
       " 'another': 152,\n",
       " '@entity24': 153,\n",
       " 'report': 154,\n",
       " 'killed': 155,\n",
       " 'way': 156,\n",
       " 'make': 157,\n",
       " 'very': 158,\n",
       " 'may': 159,\n",
       " 'down': 160,\n",
       " 'us': 161,\n",
       " 'going': 162,\n",
       " 'much': 163,\n",
       " 'does': 164,\n",
       " 'say': 165,\n",
       " 'three': 166,\n",
       " 'death': 167,\n",
       " 'between': 168,\n",
       " 'video': 169,\n",
       " \"'re\": 170,\n",
       " 'since': 171,\n",
       " 'me': 172,\n",
       " 'through': 173,\n",
       " 'well': 174,\n",
       " 'during': 175,\n",
       " 'day': 176,\n",
       " 'should': 177,\n",
       " 'know': 178,\n",
       " 'old': 179,\n",
       " 'week': 180,\n",
       " '@entity26': 181,\n",
       " 'called': 182,\n",
       " 'man': 183,\n",
       " 'such': 184,\n",
       " '@entity25': 185,\n",
       " 'see': 186,\n",
       " 'part': 187,\n",
       " 'case': 188,\n",
       " 'long': 189,\n",
       " 'military': 190,\n",
       " 'city': 191,\n",
       " 'off': 192,\n",
       " 'same': 193,\n",
       " 'around': 194,\n",
       " '@entity27': 195,\n",
       " 'reported': 196,\n",
       " ';': 197,\n",
       " 'women': 198,\n",
       " 'officer': 199,\n",
       " '@entity28': 200,\n",
       " 'take': 201,\n",
       " 'including': 202,\n",
       " 'home': 203,\n",
       " 'days': 204,\n",
       " 'work': 205,\n",
       " 'go': 206,\n",
       " 'want': 207,\n",
       " 'statement': 208,\n",
       " 'found': 209,\n",
       " 'court': 210,\n",
       " 'officials': 211,\n",
       " '$': 212,\n",
       " 'took': 213,\n",
       " 'your': 214,\n",
       " 'law': 215,\n",
       " 'come': 216,\n",
       " 'right': 217,\n",
       " 'under': 218,\n",
       " 'never': 219,\n",
       " '...': 220,\n",
       " 'attack': 221,\n",
       " 'support': 222,\n",
       " 'help': 223,\n",
       " 'thursday': 224,\n",
       " 'show': 225,\n",
       " 'here': 226,\n",
       " 'why': 227,\n",
       " 'wednesday': 228,\n",
       " '@entity29': 229,\n",
       " 'former': 230,\n",
       " '@entity30': 231,\n",
       " 'official': 232,\n",
       " 'security': 233,\n",
       " 'later': 234,\n",
       " 'good': 235,\n",
       " 'public': 236,\n",
       " 'both': 237,\n",
       " '%': 238,\n",
       " 'million': 239,\n",
       " 'too': 240,\n",
       " 'think': 241,\n",
       " 'contributed': 242,\n",
       " 'left': 243,\n",
       " 'away': 244,\n",
       " 'used': 245,\n",
       " 'whether': 246,\n",
       " 'tuesday': 247,\n",
       " 'children': 248,\n",
       " 'others': 249,\n",
       " 'own': 250,\n",
       " 'few': 251,\n",
       " 'four': 252,\n",
       " 'need': 253,\n",
       " 'really': 254,\n",
       " 'media': 255,\n",
       " 'came': 256,\n",
       " 'authorities': 257,\n",
       " 'war': 258,\n",
       " 'use': 259,\n",
       " 'wrote': 260,\n",
       " 'end': 261,\n",
       " 'men': 262,\n",
       " '@entity31': 263,\n",
       " 'officers': 264,\n",
       " 'next': 265,\n",
       " \"'ve\": 266,\n",
       " 'died': 267,\n",
       " '10': 268,\n",
       " '2013': 269,\n",
       " 'asked': 270,\n",
       " 'something': 271,\n",
       " 'five': 272,\n",
       " 'put': 273,\n",
       " 'rights': 274,\n",
       " '@entity33': 275,\n",
       " 'least': 276,\n",
       " 'every': 277,\n",
       " 'place': 278,\n",
       " 'among': 279,\n",
       " 'campaign': 280,\n",
       " 'school': 281,\n",
       " 'far': 282,\n",
       " '@entity32': 283,\n",
       " 'went': 284,\n",
       " 'forces': 285,\n",
       " 'monday': 286,\n",
       " 'taken': 287,\n",
       " 'without': 288,\n",
       " 'community': 289,\n",
       " 'young': 290,\n",
       " 'night': 291,\n",
       " \"'m\": 292,\n",
       " 'high': 293,\n",
       " 'news': 294,\n",
       " 'saying': 295,\n",
       " 'deal': 296,\n",
       " 'began': 297,\n",
       " '!': 298,\n",
       " 'little': 299,\n",
       " 'yet': 300,\n",
       " 'known': 301,\n",
       " 'past': 302,\n",
       " 'nuclear': 303,\n",
       " 'got': 304,\n",
       " 'months': 305,\n",
       " 'might': 306,\n",
       " 'hours': 307,\n",
       " '@entity35': 308,\n",
       " 'members': 309,\n",
       " 'story': 310,\n",
       " 'number': 311,\n",
       " 'nation': 312,\n",
       " 'history': 313,\n",
       " 'several': 314,\n",
       " 'across': 315,\n",
       " 'black': 316,\n",
       " 'ago': 317,\n",
       " 'march': 318,\n",
       " 'friday': 319,\n",
       " 'violence': 320,\n",
       " 'april': 321,\n",
       " 'month': 322,\n",
       " 'set': 323,\n",
       " 'trying': 324,\n",
       " 'though': 325,\n",
       " 'recent': 326,\n",
       " 'investigation': 327,\n",
       " 'shot': 328,\n",
       " 'sunday': 329,\n",
       " 'attorney': 330,\n",
       " 'already': 331,\n",
       " 'lot': 332,\n",
       " 'political': 333,\n",
       " 'car': 334,\n",
       " 'once': 335,\n",
       " 'fact': 336,\n",
       " 'until': 337,\n",
       " 'today': 338,\n",
       " '@entity34': 339,\n",
       " 'company': 340,\n",
       " 'best': 341,\n",
       " 'fight': 342,\n",
       " 'second': 343,\n",
       " 'based': 344,\n",
       " 'released': 345,\n",
       " 'international': 346,\n",
       " 'big': 347,\n",
       " 'national': 348,\n",
       " 'things': 349,\n",
       " 'different': 350,\n",
       " 'students': 351,\n",
       " 'saturday': 352,\n",
       " 'point': 353,\n",
       " 'look': 354,\n",
       " 'area': 355,\n",
       " 'minister': 356,\n",
       " '2014': 357,\n",
       " 'power': 358,\n",
       " 'making': 359,\n",
       " 'team': 360,\n",
       " 'early': 361,\n",
       " 'each': 362,\n",
       " 'again': 363,\n",
       " 'name': 364,\n",
       " 'times': 365,\n",
       " 'working': 366,\n",
       " 'able': 367,\n",
       " 'body': 368,\n",
       " 'water': 369,\n",
       " 'seen': 370,\n",
       " 'son': 371,\n",
       " 'woman': 372,\n",
       " 'shooting': 373,\n",
       " 'enough': 374,\n",
       " 'led': 375,\n",
       " 'social': 376,\n",
       " 'local': 377,\n",
       " '@entity36': 378,\n",
       " 'lost': 379,\n",
       " 'training': 380,\n",
       " 'region': 381,\n",
       " 'head': 382,\n",
       " 'change': 383,\n",
       " 'office': 384,\n",
       " 'lives': 385,\n",
       " 'wanted': 386,\n",
       " 'clear': 387,\n",
       " 'near': 388,\n",
       " 'believe': 389,\n",
       " 'attacks': 390,\n",
       " 'leaders': 391,\n",
       " 'late': 392,\n",
       " 'always': 393,\n",
       " 'mother': 394,\n",
       " 'started': 395,\n",
       " 'inside': 396,\n",
       " 'saw': 397,\n",
       " 'foreign': 398,\n",
       " 'countries': 399,\n",
       " 'run': 400,\n",
       " 'families': 401,\n",
       " 'arrested': 402,\n",
       " 'better': 403,\n",
       " 'behind': 404,\n",
       " 'top': 405,\n",
       " 'given': 406,\n",
       " 'happened': 407,\n",
       " 'less': 408,\n",
       " 'face': 409,\n",
       " 'charges': 410,\n",
       " 'federal': 411,\n",
       " 'decision': 412,\n",
       " 'human': 413,\n",
       " 'stop': 414,\n",
       " 'along': 415,\n",
       " 'live': 416,\n",
       " 'weeks': 417,\n",
       " 'spokesman': 418,\n",
       " \"'d\": 419,\n",
       " 'small': 420,\n",
       " 'find': 421,\n",
       " 'person': 422,\n",
       " 'force': 423,\n",
       " 'leader': 424,\n",
       " 'six': 425,\n",
       " 'hope': 426,\n",
       " 'issue': 427,\n",
       " 'hit': 428,\n",
       " 'keep': 429,\n",
       " 'often': 430,\n",
       " 'taking': 431,\n",
       " '20': 432,\n",
       " 'medical': 433,\n",
       " 'hard': 434,\n",
       " 'control': 435,\n",
       " 'someone': 436,\n",
       " 'sex': 437,\n",
       " 'prison': 438,\n",
       " 'announced': 439,\n",
       " 'doing': 440,\n",
       " 'miles': 441,\n",
       " 'earlier': 442,\n",
       " 'call': 443,\n",
       " 'having': 444,\n",
       " 'groups': 445,\n",
       " 'kind': 446,\n",
       " \"'ll\": 447,\n",
       " 'become': 448,\n",
       " 'religious': 449,\n",
       " 'policy': 450,\n",
       " 'ever': 451,\n",
       " 'thought': 452,\n",
       " 'held': 453,\n",
       " 'ground': 454,\n",
       " 'chief': 455,\n",
       " '@entity37': 456,\n",
       " 'incident': 457,\n",
       " 'getting': 458,\n",
       " 'dead': 459,\n",
       " 'system': 460,\n",
       " 'money': 461,\n",
       " 'marriage': 462,\n",
       " '2012': 463,\n",
       " 'series': 464,\n",
       " 'sure': 465,\n",
       " 'comes': 466,\n",
       " 'program': 467,\n",
       " 'looking': 468,\n",
       " 'however': 469,\n",
       " 'information': 470,\n",
       " 'done': 471,\n",
       " 'issues': 472,\n",
       " 'within': 473,\n",
       " 'migrants': 474,\n",
       " 'important': 475,\n",
       " 'almost': 476,\n",
       " 'full': 477,\n",
       " 'ca': 478,\n",
       " 'feel': 479,\n",
       " 'killing': 480,\n",
       " 'defense': 481,\n",
       " '1': 482,\n",
       " 'evidence': 483,\n",
       " 'involved': 484,\n",
       " '30': 485,\n",
       " 'final': 486,\n",
       " 'course': 487,\n",
       " 'must': 488,\n",
       " 'father': 489,\n",
       " 'coming': 490,\n",
       " 'added': 491,\n",
       " '@entity38': 492,\n",
       " 'play': 493,\n",
       " 'capital': 494,\n",
       " 'soon': 495,\n",
       " 'outside': 496,\n",
       " 'role': 497,\n",
       " 'states': 498,\n",
       " '2015': 499,\n",
       " 'despite': 500,\n",
       " 'give': 501,\n",
       " 'instead': 502,\n",
       " 'girls': 503,\n",
       " 'became': 504,\n",
       " 'general': 505,\n",
       " 'love': 506,\n",
       " 'terrorist': 507,\n",
       " 'together': 508,\n",
       " 'half': 509,\n",
       " 'murder': 510,\n",
       " 'himself': 511,\n",
       " 'possible': 512,\n",
       " 'nothing': 513,\n",
       " 'shows': 514,\n",
       " 'heard': 515,\n",
       " 'border': 516,\n",
       " 'continue': 517,\n",
       " 'january': 518,\n",
       " 'nearly': 519,\n",
       " 'open': 520,\n",
       " '@entity39': 521,\n",
       " 'air': 522,\n",
       " 'running': 523,\n",
       " 'terror': 524,\n",
       " 'health': 525,\n",
       " 'victims': 526,\n",
       " 'food': 527,\n",
       " 'hospital': 528,\n",
       " 'cases': 529,\n",
       " 'legal': 530,\n",
       " 'situation': 531,\n",
       " 'gun': 532,\n",
       " 'morning': 533,\n",
       " 'turned': 534,\n",
       " 'interview': 535,\n",
       " 'threat': 536,\n",
       " 'business': 537,\n",
       " '/': 538,\n",
       " 'thing': 539,\n",
       " 'free': 540,\n",
       " 'using': 541,\n",
       " 'likely': 542,\n",
       " 'front': 543,\n",
       " 'deputy': 544,\n",
       " 'fighting': 545,\n",
       " '2': 546,\n",
       " 'brother': 547,\n",
       " 'third': 548,\n",
       " 'couple': 549,\n",
       " 'attention': 550,\n",
       " 'release': 551,\n",
       " 'close': 552,\n",
       " 'agreement': 553,\n",
       " 'great': 554,\n",
       " 'large': 555,\n",
       " 'living': 556,\n",
       " 'side': 557,\n",
       " 'move': 558,\n",
       " 'safe': 559,\n",
       " 'agency': 560,\n",
       " '2011': 561,\n",
       " 'recently': 562,\n",
       " 'militants': 563,\n",
       " 'prime': 564,\n",
       " '@entity40': 565,\n",
       " 'phone': 566,\n",
       " 'everyone': 567,\n",
       " 'remains': 568,\n",
       " 'arrest': 569,\n",
       " 'drug': 570,\n",
       " 'genocide': 571,\n",
       " 'let': 572,\n",
       " 'boat': 573,\n",
       " 'line': 574,\n",
       " 'flight': 575,\n",
       " 'worked': 576,\n",
       " 'thousands': 577,\n",
       " 'season': 578,\n",
       " 'questions': 579,\n",
       " 'director': 580,\n",
       " 'received': 581,\n",
       " 'friends': 582,\n",
       " 'expected': 583,\n",
       " 'job': 584,\n",
       " 'ship': 585,\n",
       " 'charged': 586,\n",
       " 'read': 587,\n",
       " 'presidential': 588,\n",
       " 'return': 589,\n",
       " 'white': 590,\n",
       " 'building': 591,\n",
       " 'movie': 592,\n",
       " 'accused': 593,\n",
       " 'described': 594,\n",
       " 'am': 595,\n",
       " 'care': 596,\n",
       " 'fighters': 597,\n",
       " 'efforts': 598,\n",
       " 'reports': 599,\n",
       " 'camp': 600,\n",
       " 'action': 601,\n",
       " 'tried': 602,\n",
       " 'talk': 603,\n",
       " 'especially': 604,\n",
       " '@entity41': 605,\n",
       " 'real': 606,\n",
       " 'bring': 607,\n",
       " 'future': 608,\n",
       " 'anyone': 609,\n",
       " '3': 610,\n",
       " 'start': 611,\n",
       " 'means': 612,\n",
       " 'strong': 613,\n",
       " 'house': 614,\n",
       " 'child': 615,\n",
       " 'organization': 616,\n",
       " 'website': 617,\n",
       " 'matter': 618,\n",
       " 'whose': 619,\n",
       " 'try': 620,\n",
       " 'daughter': 621,\n",
       " 'leave': 622,\n",
       " 'film': 623,\n",
       " 'everything': 624,\n",
       " '15': 625,\n",
       " 'husband': 626,\n",
       " 'minutes': 627,\n",
       " 'trial': 628,\n",
       " 'weapons': 629,\n",
       " 'economic': 630,\n",
       " 'plane': 631,\n",
       " 'anything': 632,\n",
       " 'reason': 633,\n",
       " 'parents': 634,\n",
       " 'hundreds': 635,\n",
       " 'claims': 636,\n",
       " 'stand': 637,\n",
       " 'response': 638,\n",
       " 'sent': 639,\n",
       " 'simply': 640,\n",
       " 'seven': 641,\n",
       " 'scene': 642,\n",
       " '100': 643,\n",
       " 'citizens': 644,\n",
       " 'criminal': 645,\n",
       " 'itself': 646,\n",
       " 'gave': 647,\n",
       " 'process': 648,\n",
       " 'light': 649,\n",
       " 'fire': 650,\n",
       " 'party': 651,\n",
       " 'although': 652,\n",
       " 'following': 653,\n",
       " 'brought': 654,\n",
       " 'key': 655,\n",
       " 'freedom': 656,\n",
       " 'words': 657,\n",
       " 'troops': 658,\n",
       " 'residents': 659,\n",
       " 'areas': 660,\n",
       " 'moment': 661,\n",
       " 'tell': 662,\n",
       " 'aid': 663,\n",
       " 'include': 664,\n",
       " 'bad': 665,\n",
       " 'makes': 666,\n",
       " 'hand': 667,\n",
       " 'played': 668,\n",
       " 'century': 669,\n",
       " 'immediately': 670,\n",
       " 'special': 671,\n",
       " 'prosecutors': 672,\n",
       " 'member': 673,\n",
       " 'major': 674,\n",
       " 'serious': 675,\n",
       " 'race': 676,\n",
       " 'current': 677,\n",
       " 'justice': 678,\n",
       " 'injured': 679,\n",
       " 'actually': 680,\n",
       " 'investigators': 681,\n",
       " 'december': 682,\n",
       " 'helped': 683,\n",
       " '@entity42': 684,\n",
       " 'affiliate': 685,\n",
       " 'airstrikes': 686,\n",
       " 'civil': 687,\n",
       " 'needs': 688,\n",
       " 'felt': 689,\n",
       " '[': 690,\n",
       " ']': 691,\n",
       " 'rather': 692,\n",
       " 'single': 693,\n",
       " 'february': 694,\n",
       " 'remain': 695,\n",
       " 'posted': 696,\n",
       " 'perhaps': 697,\n",
       " 'trip': 698,\n",
       " 'provide': 699,\n",
       " '8': 700,\n",
       " 'knew': 701,\n",
       " 'source': 702,\n",
       " 'church': 703,\n",
       " 'game': 704,\n",
       " 'appeared': 705,\n",
       " 'june': 706,\n",
       " 'friend': 707,\n",
       " 'happy': 708,\n",
       " 'potential': 709,\n",
       " 'senior': 710,\n",
       " 'oil': 711,\n",
       " 'gay': 712,\n",
       " 'service': 713,\n",
       " '5': 714,\n",
       " 'word': 715,\n",
       " 'pay': 716,\n",
       " 'fans': 717,\n",
       " 'dr.': 718,\n",
       " 'sea': 719,\n",
       " 'vote': 720,\n",
       " 'wife': 721,\n",
       " 'wo': 722,\n",
       " 'safety': 723,\n",
       " 'sanctions': 724,\n",
       " 'tv': 725,\n",
       " 'search': 726,\n",
       " 'themselves': 727,\n",
       " 'university': 728,\n",
       " 'forward': 729,\n",
       " 'mean': 730,\n",
       " 'decades': 731,\n",
       " 'soldiers': 732,\n",
       " '12': 733,\n",
       " 'lead': 734,\n",
       " 'idea': 735,\n",
       " 'age': 736,\n",
       " 'problem': 737,\n",
       " '2016': 738,\n",
       " 'order': 739,\n",
       " 'further': 740,\n",
       " 'suspect': 741,\n",
       " 'claimed': 742,\n",
       " 'risk': 743,\n",
       " 'hands': 744,\n",
       " 'lawyer': 745,\n",
       " 'crime': 746,\n",
       " 'plan': 747,\n",
       " 'born': 748,\n",
       " 'fired': 749,\n",
       " 'judge': 750,\n",
       " 'reach': 751,\n",
       " 'blood': 752,\n",
       " 'needed': 753,\n",
       " 'relations': 754,\n",
       " 'sometimes': 755,\n",
       " 'met': 756,\n",
       " 'believed': 757,\n",
       " 'true': 758,\n",
       " 'dangerous': 759,\n",
       " 'workers': 760,\n",
       " 'example': 761,\n",
       " 'charge': 762,\n",
       " 'win': 763,\n",
       " 'administration': 764,\n",
       " 'terrorism': 765,\n",
       " 'hour': 766,\n",
       " '4': 767,\n",
       " 'event': 768,\n",
       " 'toward': 769,\n",
       " 'wants': 770,\n",
       " 'missing': 771,\n",
       " 'doctors': 772,\n",
       " '25': 773,\n",
       " 'fear': 774,\n",
       " 'join': 775,\n",
       " 'turn': 776,\n",
       " 'remember': 777,\n",
       " 'parts': 778,\n",
       " 'town': 779,\n",
       " 'ran': 780,\n",
       " 'experience': 781,\n",
       " 'question': 782,\n",
       " 'actions': 783,\n",
       " 'reached': 784,\n",
       " 'book': 785,\n",
       " 'television': 786,\n",
       " 'no.': 787,\n",
       " 'showed': 788,\n",
       " 'hear': 789,\n",
       " 'suffered': 790,\n",
       " 'ended': 791,\n",
       " 'documents': 792,\n",
       " 'alleged': 793,\n",
       " 'entire': 794,\n",
       " 'coalition': 795,\n",
       " 'bomb': 796,\n",
       " 'finally': 797,\n",
       " 'rebels': 798,\n",
       " 'land': 799,\n",
       " 'events': 800,\n",
       " 'plans': 801,\n",
       " 'rescue': 802,\n",
       " 'challenge': 803,\n",
       " 'watch': 804,\n",
       " 'talking': 805,\n",
       " 'streets': 806,\n",
       " 'similar': 807,\n",
       " 'jury': 808,\n",
       " 'forced': 809,\n",
       " 'site': 810,\n",
       " 'staff': 811,\n",
       " 'arrived': 812,\n",
       " 'visit': 813,\n",
       " 'comment': 814,\n",
       " 'understand': 815,\n",
       " 'gone': 816,\n",
       " 'weekend': 817,\n",
       " 'door': 818,\n",
       " 'result': 819,\n",
       " 'rest': 820,\n",
       " '24': 821,\n",
       " 'base': 822,\n",
       " 'list': 823,\n",
       " 'leaving': 824,\n",
       " '2010': 825,\n",
       " 'meeting': 826,\n",
       " 'education': 827,\n",
       " 'camera': 828,\n",
       " 'records': 829,\n",
       " 'moved': 830,\n",
       " 'difficult': 831,\n",
       " 'student': 832,\n",
       " 'message': 833,\n",
       " 'nations': 834,\n",
       " '@entity44': 835,\n",
       " '50': 836,\n",
       " 'problems': 837,\n",
       " 'largest': 838,\n",
       " 'includes': 839,\n",
       " 'room': 840,\n",
       " 'enforcement': 841,\n",
       " 'opinion': 842,\n",
       " 'latest': 843,\n",
       " 'conflict': 844,\n",
       " 'sheriff': 845,\n",
       " 'winning': 846,\n",
       " 'decided': 847,\n",
       " 'term': 848,\n",
       " 'short': 849,\n",
       " 'space': 850,\n",
       " '14': 851,\n",
       " 'easy': 852,\n",
       " 'calling': 853,\n",
       " 'details': 854,\n",
       " 'star': 855,\n",
       " 'southern': 856,\n",
       " 'carried': 857,\n",
       " 'secretary': 858,\n",
       " 'hold': 859,\n",
       " 'speech': 860,\n",
       " 'significant': 861,\n",
       " 'assault': 862,\n",
       " 'heart': 863,\n",
       " 'spoke': 864,\n",
       " 'class': 865,\n",
       " '18': 866,\n",
       " '@entity43': 867,\n",
       " 'loved': 868,\n",
       " 'fled': 869,\n",
       " 'mass': 870,\n",
       " 'form': 871,\n",
       " 'online': 872,\n",
       " 'date': 873,\n",
       " 'seems': 874,\n",
       " 'allowed': 875,\n",
       " 'signed': 876,\n",
       " 'faces': 877,\n",
       " 'eight': 878,\n",
       " 'failed': 879,\n",
       " 'effort': 880,\n",
       " 'p.m.': 881,\n",
       " 'street': 882,\n",
       " 'voice': 883,\n",
       " 'tells': 884,\n",
       " 'board': 885,\n",
       " 'protect': 886,\n",
       " 'cause': 887,\n",
       " 'music': 888,\n",
       " 'reporters': 889,\n",
       " 'armed': 890,\n",
       " 'chance': 891,\n",
       " 'economy': 892,\n",
       " 'travel': 893,\n",
       " 'kill': 894,\n",
       " 'filed': 895,\n",
       " 'protests': 896,\n",
       " 'girl': 897,\n",
       " 'crisis': 898,\n",
       " 'whom': 899,\n",
       " 'denied': 900,\n",
       " 'september': 901,\n",
       " 'reporter': 902,\n",
       " 'guilty': 903,\n",
       " 'crew': 904,\n",
       " 'crash': 905,\n",
       " 'november': 906,\n",
       " 'step': 907,\n",
       " 'department': 908,\n",
       " 'yes': 909,\n",
       " 'earthquake': 910,\n",
       " 'act': 911,\n",
       " 'named': 912,\n",
       " 'character': 913,\n",
       " 'opportunity': 914,\n",
       " 'eyes': 915,\n",
       " '—': 916,\n",
       " 'wrong': 917,\n",
       " 'waiting': 918,\n",
       " 'caught': 919,\n",
       " 'majority': 920,\n",
       " 'continued': 921,\n",
       " 'growing': 922,\n",
       " 'bill': 923,\n",
       " 'patients': 924,\n",
       " 'personal': 925,\n",
       " 'meanwhile': 926,\n",
       " 'stay': 927,\n",
       " 'sense': 928,\n",
       " 'bombing': 929,\n",
       " 'stories': 930,\n",
       " 'mostly': 931,\n",
       " 'won': 932,\n",
       " 'points': 933,\n",
       " 'debate': 934,\n",
       " '&': 935,\n",
       " 'related': 936,\n",
       " 'popular': 937,\n",
       " 'sen.': 938,\n",
       " 'leading': 939,\n",
       " 'alone': 940,\n",
       " '#': 941,\n",
       " 'convicted': 942,\n",
       " 'center': 943,\n",
       " 'record': 944,\n",
       " '16': 945,\n",
       " 'allies': 946,\n",
       " 'population': 947,\n",
       " 'joined': 948,\n",
       " 'trade': 949,\n",
       " 'protesters': 950,\n",
       " 'operation': 951,\n",
       " 'battle': 952,\n",
       " 'access': 953,\n",
       " 'mr.': 954,\n",
       " 'mission': 955,\n",
       " 'biggest': 956,\n",
       " 'degree': 957,\n",
       " 'due': 958,\n",
       " 'changed': 959,\n",
       " 'route': 960,\n",
       " 'sister': 961,\n",
       " 'a.m.': 962,\n",
       " 'deaths': 963,\n",
       " 'northern': 964,\n",
       " 'address': 965,\n",
       " 'appears': 966,\n",
       " 'passed': 967,\n",
       " 'allegedly': 968,\n",
       " 'ships': 969,\n",
       " 'common': 970,\n",
       " 'identified': 971,\n",
       " 'penalty': 972,\n",
       " 'longer': 973,\n",
       " 'paid': 974,\n",
       " 'climate': 975,\n",
       " 'allow': 976,\n",
       " 'cut': 977,\n",
       " 'journey': 978,\n",
       " 'vehicle': 979,\n",
       " 'die': 980,\n",
       " 'whole': 981,\n",
       " 'speak': 982,\n",
       " 'bodies': 983,\n",
       " '11': 984,\n",
       " 'nine': 985,\n",
       " 'claim': 986,\n",
       " 'calls': 987,\n",
       " 'quickly': 988,\n",
       " 'transgender': 989,\n",
       " 'alive': 990,\n",
       " 'fellow': 991,\n",
       " 'usually': 992,\n",
       " 'mind': 993,\n",
       " 'meet': 994,\n",
       " '200': 995,\n",
       " 'august': 996,\n",
       " 'beyond': 997,\n",
       " 'responsibility': 998,\n",
       " 'seemed': 999,\n",
       " 'activists': 1000,\n",
       " 'services': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voc.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_rand_train_pair():\n",
    "#     expl_idx = random.randrange(0, len(test_documents))\n",
    "    \n",
    "#     return test_documents[expl_idx], test_questions[expl_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a list of indexes, one for each word in the sentence\n",
    "# def indexes_from_sentence(voc, sentence):\n",
    "#     return [voc.get_word2index(word) for word in sentence.split(' ')]\n",
    "\n",
    "# def variable_from_sentence(voc, sentence):\n",
    "#     indexes = indexes_from_sentence(voc, sentence)\n",
    "#     indexes.append(delimiter)\n",
    "#     var = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "#     if USE_CUDA: \n",
    "#         var = var.cuda()\n",
    "#     return var\n",
    "\n",
    "# def variables_from_pair(doc, question):\n",
    "#     input_variable = variable_from_sentence(voc, doc)\n",
    "#     target_variable = variable_from_sentence(voc, question)\n",
    "#     return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "    def forward(self, word_inputs, hidden):\n",
    "        # Note: we run this all at once (over the whole input sequence)\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA: hidden = hidden.cuda()\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn(\"concat\", hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        # Note that we will only be running forward for a single decoder time step, but will use all encoder outputs\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        wAttnDecoderRNNord_embedded = self.dropout(word_embedded)\n",
    "        \n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        \n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        \n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.other = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        seq_len = len(encoder_outputs)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(seq_len)) # B x 1 x S\n",
    "        if USE_CUDA: attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # Calculate energies for each encoder output\n",
    "        for i in range(seq_len):\n",
    "            attn_energies[i] = self.score(hidden, encoder_outputs[i])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x 1 x seq_len\n",
    "        return F.softmax(attn_energies).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_output):\n",
    "        \n",
    "        if self.method == 'dot':\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "            return energy\n",
    "        \n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = torch.dot(self.other.view(-1), energy.view(-1))\n",
    "            return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        # Keep parameters for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size * 2, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size * 2, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "    \n",
    "    def forward(self, word_input, last_context, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step at a time\n",
    "        \n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1) # S=1 x B x N\n",
    "        \n",
    "        # Combine embedded input word and last context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, last_context.unsqueeze(0)), 2)\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "        attn_weights = self.attn(rnn_output.squeeze(0), encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        \n",
    "        # Final output layer (next word prediction) using the RNN hidden state and context vector\n",
    "        rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        \n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2)\n",
      ")\n",
      "AttnDecoderRNN (\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(20, 10, num_layers=2, dropout=0.1)\n",
      "  (out): Linear (20 -> 10)\n",
      "  (attn): Attn (\n",
      "    (attn): Linear (10 -> 10)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n",
      "torch.Size([1, 10]) torch.Size([2, 1, 10]) torch.Size([1, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = AttnDecoderRNN('general', 10, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)\n",
    "\n",
    "encoder_hidden = encoder_test.init_hidden()\n",
    "word_input = Variable(torch.LongTensor([1, 2, 3]))\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     encoder_test = nn.DataParallel(encoder_test)\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder_test.cuda()\n",
    "    word_input = word_input.cuda()\n",
    "encoder_outputs, encoder_hidden = encoder_test(word_input, encoder_hidden)\n",
    "\n",
    "word_inputs = Variable(torch.LongTensor([1, 2, 3]))\n",
    "decoder_attns = torch.zeros(1, 3, 3)\n",
    "decoder_hidden = encoder_hidden\n",
    "decoder_context = Variable(torch.zeros(1, decoder_test.hidden_size))\n",
    "\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     decoder_test = nn.DataParallel(decoder_test)\n",
    "\n",
    "if USE_CUDA:\n",
    "    decoder_test.cuda()\n",
    "    word_inputs = word_inputs.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "    \n",
    "\n",
    "for i in range(3):\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder_test(word_inputs[i], decoder_context, \n",
    "                                                                                 decoder_hidden, \n",
    "                                                                                 encoder_outputs)\n",
    "    print(decoder_output.size(), decoder_hidden.size(), decoder_attn.size())\n",
    "    decoder_attns[0, i] = decoder_attn.squeeze(0).cpu().data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "clip = 5.0\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "\n",
    "    # Zero gradients of both optimizers\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0 # Added onto for each word\n",
    "\n",
    "    # Get size of input and target sentences\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    # Run words through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "    \n",
    "    # Prepare input and output variables\n",
    "    decoder_input = Variable(torch.LongTensor([[delimiter]]))\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Choose whether to use teacher forcing\n",
    "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Teacher forcing: Use the ground-truth target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            #print(decoder_output[0])\n",
    "            #print(target_variable[0])\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di] # Next target is next input\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use network's own prediction as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "            #print(decoder_output[0])\n",
    "            #print(target_variable[0])\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            \n",
    "            # Get most likely word index (highest value) from output\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]])) # Chosen word is next input\n",
    "            if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "            # Stop at end of sentence (not necessary when using known targets)\n",
    "            if ni == delimiter: break\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attn_model = 'general'\n",
    "hidden_size = 500\n",
    "n_layers = 2\n",
    "dropout_p = 0.05\n",
    "\n",
    "# Initialize models\n",
    "encoder = EncoderRNN(voc.n_words, hidden_size, n_layers)\n",
    "decoder = AttnDecoderRNN(attn_model, hidden_size, voc.n_words, n_layers, dropout_p=dropout_p)\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "# Initialize optimizers and criterion\n",
    "learning_rate = 0.0001\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configuring training\n",
    "n_epochs = 50000\n",
    "plot_every = 200\n",
    "print_every = 2\n",
    "\n",
    "# Keep track of time elapsed and running averages\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0 # Reset every print_every\n",
    "plot_loss_total = 0 # Reset every plot_every\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 12s (- 5412m 55s) (2 0%) 7.1693\n",
      "0m 15s (- 3290m 12s) (4 0%) 2.4181\n",
      "0m 34s (- 4752m 57s) (6 0%) 6.6089\n",
      "0m 55s (- 5779m 25s) (8 0%) 4.8478\n",
      "1m 5s (- 5491m 8s) (10 0%) 5.0648\n",
      "unknown word\n",
      "1m 15s (- 5216m 39s) (12 0%) 4.5302\n",
      "1m 17s (- 4603m 58s) (14 0%) 3.0104\n",
      "1m 31s (- 4756m 40s) (16 0%) 6.0935\n",
      "1m 46s (- 4911m 18s) (18 0%) 4.5574\n",
      "1m 59s (- 4988m 58s) (20 0%) 7.1703\n",
      "2m 11s (- 4974m 17s) (22 0%) 7.2186\n",
      "2m 19s (- 4857m 27s) (24 0%) 4.4690\n",
      "2m 46s (- 5345m 4s) (26 0%) 4.4922\n",
      "2m 59s (- 5338m 30s) (28 0%) 5.1818\n",
      "3m 4s (- 5122m 41s) (30 0%) 2.2866\n",
      "3m 8s (- 4915m 30s) (32 0%) 5.5298\n",
      "3m 21s (- 4927m 45s) (34 0%) 5.0381\n",
      "3m 39s (- 5072m 29s) (36 0%) 7.9021\n",
      "3m 46s (- 4961m 9s) (38 0%) 5.4775\n",
      "4m 1s (- 5031m 32s) (40 0%) 4.5732\n",
      "unknown word\n",
      "4m 23s (- 5227m 20s) (42 0%) 5.0258\n",
      "4m 31s (- 5145m 29s) (44 0%) 6.3884\n",
      "unknown word\n",
      "4m 41s (- 5100m 9s) (46 0%) 5.5603\n",
      "4m 49s (- 5023m 7s) (48 0%) 4.3538\n",
      "4m 53s (- 4879m 5s) (50 0%) 5.6833\n",
      "5m 6s (- 4903m 41s) (52 0%) 4.5040\n",
      "5m 23s (- 4984m 53s) (54 0%) 4.8067\n",
      "5m 32s (- 4948m 52s) (56 0%) 5.3534\n",
      "unknown word\n",
      "5m 39s (- 4870m 52s) (58 0%) 5.1916\n",
      "5m 55s (- 4931m 34s) (60 0%) 7.7045\n",
      "5m 58s (- 4813m 44s) (62 0%) 7.3243\n",
      "6m 8s (- 4794m 28s) (64 0%) 5.8595\n",
      "6m 12s (- 4699m 43s) (66 0%) 7.8696\n",
      "unknown word\n",
      "6m 20s (- 4651m 29s) (68 0%) 2.3365\n",
      "6m 25s (- 4577m 7s) (70 0%) 7.5894\n",
      "6m 49s (- 4733m 11s) (72 0%) 6.3874\n",
      "7m 1s (- 4741m 51s) (74 0%) 5.7984\n",
      "7m 12s (- 4734m 53s) (76 0%) 4.9808\n",
      "7m 38s (- 4890m 53s) (78 0%) 4.5308\n",
      "7m 45s (- 4838m 23s) (80 0%) 5.2013\n",
      "7m 56s (- 4835m 35s) (82 0%) 6.4935\n",
      "7m 59s (- 4751m 42s) (84 0%) 6.2152\n",
      "8m 16s (- 4799m 0s) (86 0%) 5.6020\n",
      "8m 36s (- 4882m 7s) (88 0%) 6.5783\n",
      "8m 47s (- 4878m 59s) (90 0%) 7.5424\n",
      "9m 12s (- 4996m 4s) (92 0%) 6.5880\n",
      "unknown word\n",
      "9m 21s (- 4971m 23s) (94 0%) 2.3725\n",
      "9m 43s (- 5054m 6s) (96 0%) 4.8164\n",
      "9m 47s (- 4989m 7s) (98 0%) 5.0989\n",
      "9m 58s (- 4977m 17s) (100 0%) 2.9899\n",
      "10m 14s (- 5006m 46s) (102 0%) 5.5295\n",
      "10m 27s (- 5014m 31s) (104 0%) 4.7705\n",
      "10m 32s (- 4962m 27s) (106 0%) 3.9275\n",
      "10m 41s (- 4942m 31s) (108 0%) 2.9209\n",
      "unknown word\n",
      "11m 2s (- 5005m 51s) (110 0%) 5.6086\n",
      "11m 14s (- 5007m 13s) (112 0%) 3.8960\n",
      "11m 19s (- 4957m 21s) (114 0%) 5.7525\n",
      "11m 29s (- 4943m 37s) (116 0%) 3.1912\n",
      "11m 39s (- 4926m 13s) (118 0%) 6.3494\n",
      "11m 44s (- 4881m 59s) (120 0%) 6.9447\n",
      "11m 49s (- 4832m 16s) (122 0%) 5.2799\n",
      "unknown word\n",
      "11m 57s (- 4811m 13s) (124 0%) 5.6418\n",
      "12m 1s (- 4761m 42s) (126 0%) 3.4558\n",
      "12m 6s (- 4716m 4s) (128 0%) 6.4353\n",
      "12m 11s (- 4677m 19s) (130 0%) 2.9105\n",
      "12m 19s (- 4655m 19s) (132 0%) 7.7614\n",
      "12m 55s (- 4811m 33s) (134 0%) 6.7470\n",
      "13m 9s (- 4822m 21s) (136 0%) 5.4551\n",
      "13m 14s (- 4787m 16s) (138 0%) 5.4293\n",
      "13m 30s (- 4809m 41s) (140 0%) 6.8693\n",
      "13m 44s (- 4823m 9s) (142 0%) 3.8935\n",
      "13m 50s (- 4790m 19s) (144 0%) 3.6122\n",
      "13m 59s (- 4779m 19s) (146 0%) 6.9906\n",
      "14m 13s (- 4793m 40s) (148 0%) 6.5478\n",
      "14m 22s (- 4778m 9s) (150 0%) 5.5666\n",
      "14m 29s (- 4752m 33s) (152 0%) 7.2506\n",
      "14m 52s (- 4816m 26s) (154 0%) 7.4781\n",
      "15m 0s (- 4793m 18s) (156 0%) 4.6996\n",
      "15m 16s (- 4817m 9s) (158 0%) 6.3408\n",
      "15m 26s (- 4809m 13s) (160 0%) 4.3046\n",
      "15m 30s (- 4770m 2s) (162 0%) 6.1093\n",
      "15m 45s (- 4790m 11s) (164 0%) 6.7454\n",
      "15m 49s (- 4751m 57s) (166 0%) 4.5583\n",
      "16m 3s (- 4763m 3s) (168 0%) 3.2308\n",
      "16m 14s (- 4761m 19s) (170 0%) 4.3890\n",
      "unknown word\n",
      "16m 28s (- 4771m 50s) (172 0%) 4.4447\n",
      "unknown word\n",
      "16m 45s (- 4798m 3s) (174 0%) 4.8717\n",
      "17m 3s (- 4829m 14s) (176 0%) 5.7662\n",
      "17m 15s (- 4828m 46s) (178 0%) 6.7275\n",
      "17m 22s (- 4808m 38s) (180 0%) 6.8540\n",
      "17m 29s (- 4787m 56s) (182 0%) 4.8654\n",
      "17m 36s (- 4767m 50s) (184 0%) 6.9285\n",
      "unknown word\n",
      "17m 45s (- 4756m 24s) (186 0%) 5.1574\n",
      "17m 59s (- 4767m 22s) (188 0%) 5.4834\n",
      "18m 20s (- 4809m 27s) (190 0%) 6.8914\n",
      "18m 30s (- 4802m 11s) (192 0%) 5.6028\n",
      "18m 39s (- 4790m 42s) (194 0%) 6.4060\n",
      "18m 58s (- 4823m 14s) (196 0%) 4.4075\n",
      "19m 5s (- 4804m 7s) (198 0%) 4.0541\n",
      "19m 10s (- 4772m 51s) (200 0%) 4.7868\n",
      "unknown word\n",
      "19m 23s (- 4778m 43s) (202 0%) 4.7445\n",
      "19m 26s (- 4744m 23s) (204 0%) 4.1322\n",
      "19m 34s (- 4730m 34s) (206 0%) 5.8149\n",
      "19m 50s (- 4748m 16s) (208 0%) 6.7411\n",
      "unknown word\n",
      "19m 59s (- 4741m 23s) (210 0%) 5.7481\n",
      "20m 10s (- 4737m 7s) (212 0%) 5.8090\n",
      "20m 16s (- 4715m 52s) (214 0%) 5.5064\n",
      "20m 38s (- 4758m 43s) (216 0%) 6.4438\n",
      "20m 52s (- 4767m 25s) (218 0%) 4.1896\n",
      "21m 6s (- 4776m 32s) (220 0%) 6.2554\n",
      "21m 16s (- 4769m 59s) (222 0%) 5.0699\n",
      "21m 26s (- 4763m 32s) (224 0%) 5.6407\n",
      "21m 43s (- 4783m 15s) (226 0%) 5.5543\n",
      "21m 52s (- 4776m 5s) (228 0%) 5.1171\n",
      "unknown word\n",
      "22m 0s (- 4762m 14s) (230 0%) 6.9468\n",
      "22m 10s (- 4757m 15s) (232 0%) 7.0507\n",
      "22m 16s (- 4737m 16s) (234 0%) 4.7259\n",
      "22m 27s (- 4734m 23s) (236 0%) 5.0164\n",
      "22m 43s (- 4752m 35s) (238 0%) 4.3476\n",
      "22m 53s (- 4747m 37s) (240 0%) 5.3112\n",
      "23m 2s (- 4738m 19s) (242 0%) 6.3291\n",
      "23m 14s (- 4739m 8s) (244 0%) 7.4074\n",
      "unknown word\n",
      "23m 25s (- 4739m 16s) (246 0%) 6.7446\n",
      "unknown word\n",
      "23m 42s (- 4756m 51s) (248 0%) 5.0917\n",
      "23m 53s (- 4752m 47s) (250 0%) 4.3019\n",
      "24m 15s (- 4787m 56s) (252 0%) 6.8962\n",
      "24m 34s (- 4812m 53s) (254 0%) 7.0427\n",
      "24m 56s (- 4846m 57s) (256 0%) 6.7779\n",
      "25m 7s (- 4843m 14s) (258 0%) 6.6307\n",
      "25m 30s (- 4881m 1s) (260 0%) 7.3463\n",
      "unknown word\n",
      "25m 46s (- 4892m 25s) (262 0%) 3.8527\n",
      "25m 59s (- 4896m 31s) (264 0%) 6.5164\n",
      "26m 8s (- 4886m 14s) (266 0%) 7.8351\n",
      "26m 20s (- 4886m 39s) (268 0%) 5.1682\n",
      "unknown word\n",
      "26m 42s (- 4918m 12s) (270 0%) 5.1736\n",
      "26m 49s (- 4904m 35s) (272 0%) 6.1232\n",
      "27m 0s (- 4901m 4s) (274 0%) 4.2069\n",
      "27m 20s (- 4926m 38s) (276 0%) 6.2009\n",
      "27m 29s (- 4918m 21s) (278 0%) 5.6001\n",
      "27m 35s (- 4899m 21s) (280 0%) 6.2265\n",
      "27m 49s (- 4905m 23s) (282 0%) 5.8002\n",
      "28m 10s (- 4932m 29s) (284 0%) 6.6490\n",
      "28m 25s (- 4941m 54s) (286 0%) 6.2620\n",
      "28m 37s (- 4942m 19s) (288 0%) 5.5293\n",
      "28m 49s (- 4942m 4s) (290 0%) 5.2452\n",
      "28m 59s (- 4935m 28s) (292 0%) 6.4264\n",
      "29m 13s (- 4940m 48s) (294 0%) 3.1539\n",
      "29m 25s (- 4940m 14s) (296 0%) 5.0918\n",
      "29m 45s (- 4962m 39s) (298 0%) 4.4696\n",
      "unknown word\n",
      "29m 58s (- 4964m 41s) (300 0%) 3.6521\n",
      "30m 17s (- 4983m 53s) (302 0%) 6.6053\n",
      "30m 25s (- 4974m 54s) (304 0%) 6.5576\n",
      "30m 40s (- 4981m 12s) (306 0%) 5.5528\n",
      "31m 2s (- 5007m 27s) (308 0%) 7.5428\n",
      "31m 12s (- 5001m 32s) (310 0%) 6.8773\n",
      "31m 20s (- 4991m 16s) (312 0%) 4.5526\n",
      "unknown word\n",
      "31m 45s (- 5026m 36s) (314 0%) 6.6639\n",
      "32m 3s (- 5040m 49s) (316 0%) 4.7773\n",
      "32m 28s (- 5072m 45s) (318 0%) 3.4320\n",
      "32m 44s (- 5082m 3s) (320 0%) 4.8564\n",
      "32m 48s (- 5062m 45s) (322 0%) 5.6408\n",
      "unknown word\n",
      "33m 4s (- 5071m 33s) (324 0%) 6.2161\n",
      "33m 25s (- 5092m 54s) (326 0%) 6.5768\n",
      "33m 42s (- 5104m 51s) (328 0%) 6.5200\n",
      "34m 2s (- 5123m 49s) (330 0%) 6.4299\n",
      "34m 27s (- 5155m 2s) (332 0%) 6.4963\n",
      "unknown word\n",
      "34m 36s (- 5146m 12s) (334 0%) 5.2331\n",
      "unknown word\n",
      "34m 46s (- 5140m 5s) (336 0%) 6.8907\n",
      "34m 57s (- 5136m 40s) (338 0%) 4.9888\n",
      "35m 6s (- 5128m 17s) (340 0%) 6.4821\n",
      "35m 18s (- 5127m 22s) (342 0%) 7.3591\n",
      "35m 28s (- 5120m 24s) (344 0%) 6.4867\n",
      "35m 52s (- 5147m 45s) (346 0%) 7.8874\n",
      "36m 16s (- 5176m 33s) (348 0%) 5.9551\n",
      "36m 28s (- 5174m 58s) (350 0%) 4.0321\n",
      "36m 52s (- 5202m 4s) (352 0%) 6.4616\n",
      "37m 2s (- 5194m 31s) (354 0%) 5.8842\n",
      "37m 14s (- 5193m 29s) (356 0%) 6.3068\n",
      "37m 39s (- 5221m 9s) (358 0%) 6.9821\n",
      "37m 59s (- 5239m 29s) (360 0%) 6.1860\n",
      "38m 27s (- 5272m 45s) (362 0%) 6.0513\n",
      "38m 38s (- 5268m 45s) (364 0%) 6.1611\n",
      "38m 51s (- 5269m 43s) (366 0%) 5.7536\n",
      "39m 10s (- 5283m 3s) (368 0%) 6.7151\n",
      "39m 38s (- 5317m 51s) (370 0%) 5.6549\n",
      "unknown word\n",
      "39m 43s (- 5298m 54s) (372 0%) 6.4187\n",
      "unknown word\n",
      "39m 52s (- 5290m 42s) (374 0%) 5.6981\n",
      "39m 58s (- 5274m 52s) (376 0%) 4.5795\n",
      "40m 7s (- 5266m 22s) (378 0%) 2.5733\n",
      "40m 13s (- 5253m 17s) (380 0%) 6.6388\n",
      "unknown word\n",
      "40m 30s (- 5261m 59s) (382 0%) 4.6360\n",
      "40m 39s (- 5253m 0s) (384 0%) 6.8474\n",
      "40m 48s (- 5245m 20s) (386 0%) 4.3795\n",
      "40m 57s (- 5237m 21s) (388 0%) 3.3937\n",
      "41m 4s (- 5225m 5s) (390 0%) 6.3144\n",
      "41m 13s (- 5216m 24s) (392 0%) 3.4097\n",
      "41m 21s (- 5206m 18s) (394 0%) 7.5520\n",
      "41m 33s (- 5206m 42s) (396 0%) 6.4743\n",
      "41m 42s (- 5198m 39s) (398 0%) 5.5307\n",
      "41m 58s (- 5204m 28s) (400 0%) 6.7742\n",
      "42m 8s (- 5198m 24s) (402 0%) 6.7496\n",
      "42m 17s (- 5191m 53s) (404 0%) 6.2737\n",
      "unknown word\n",
      "42m 39s (- 5210m 47s) (406 0%) 7.4931\n",
      "unknown word\n",
      "42m 50s (- 5207m 6s) (408 0%) 5.1701\n",
      "43m 12s (- 5227m 2s) (410 0%) 4.7982\n",
      "43m 44s (- 5265m 22s) (412 0%) 7.1925\n",
      "43m 57s (- 5265m 14s) (414 0%) 7.0682\n",
      "44m 15s (- 5275m 37s) (416 0%) 7.4647\n",
      "44m 20s (- 5258m 51s) (418 0%) 5.7989\n",
      "44m 34s (- 5261m 35s) (420 0%) 6.8909\n",
      "44m 43s (- 5253m 54s) (422 0%) 6.2182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45m 0s (- 5261m 51s) (424 0%) 4.6339\n",
      "45m 19s (- 5275m 1s) (426 0%) 5.6503\n",
      "45m 28s (- 5266m 15s) (428 0%) 6.9123\n",
      "45m 42s (- 5269m 26s) (430 0%) 6.5278\n",
      "45m 59s (- 5276m 37s) (432 0%) 5.9981\n",
      "46m 8s (- 5269m 45s) (434 0%) 5.8148\n",
      "46m 17s (- 5261m 33s) (436 0%) 3.1820\n",
      "46m 33s (- 5267m 32s) (438 0%) 4.8042\n",
      "46m 42s (- 5260m 34s) (440 0%) 7.1870\n",
      "47m 4s (- 5277m 15s) (442 0%) 5.5655\n",
      "47m 17s (- 5277m 51s) (444 0%) 4.7664\n",
      "47m 34s (- 5286m 0s) (446 0%) 6.0398\n",
      "47m 42s (- 5276m 1s) (448 0%) 5.0665\n",
      "47m 54s (- 5275m 18s) (450 0%) 6.8057\n",
      "48m 5s (- 5271m 16s) (452 0%) 4.6615\n",
      "48m 19s (- 5273m 36s) (454 0%) 6.8420\n",
      "48m 30s (- 5271m 5s) (456 0%) 6.2633\n",
      "48m 50s (- 5282m 20s) (458 0%) 5.9657\n",
      "48m 53s (- 5266m 13s) (460 0%) 4.7154\n",
      "49m 12s (- 5276m 48s) (462 0%) 5.2106\n",
      "49m 26s (- 5278m 33s) (464 0%) 7.4589\n",
      "49m 40s (- 5280m 56s) (466 0%) 7.1804\n",
      "49m 45s (- 5265m 51s) (468 0%) 5.1664\n",
      "49m 57s (- 5264m 49s) (470 0%) 4.7927\n",
      "50m 5s (- 5256m 57s) (472 0%) 5.3310\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-19186fe70f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(input_variable)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Run the train function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Keep track of loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-01bab32ad137>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin!\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    \n",
    "    # Get training data for this cycle\n",
    "    pair = get_rand_train_pair()\n",
    "    input_variable = variable_from_sentence(voc, pair[0])\n",
    "    target_variable = variable_from_sentence(voc, pair[1])\n",
    "    #print(input_variable)\n",
    "    # Run the train function\n",
    "    loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "\n",
    "    # Keep track of loss\n",
    "    print_loss_total += loss\n",
    "    plot_loss_total += loss\n",
    "\n",
    "    if epoch == 0: continue\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print_loss_avg = print_loss_total / print_every\n",
    "        print_loss_total = 0\n",
    "        print_summary = '%s (%d %d%%) %.4f' % (time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "        print(print_summary)\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        plot_loss_avg = plot_loss_total / plot_every\n",
    "        plot_losses.append(plot_loss_avg)\n",
    "        plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4ad076dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nApDCXUQkACncRUQC0P8Dga4LvVignGcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4a4cd70f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def show_plot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2) # put ticks at regular intervals\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "show_plot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, max_length=200):\n",
    "    input_variable = variable_from_sentence(voc, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    \n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.init_hidden()\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([[delimiter]])) # SOS\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "    \n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == delimiter:\n",
    "            decoded_words.append('|||')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(voc.index2word[ni])\n",
    "            \n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "    \n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_randomly():\n",
    "    pair = get_rand_train_pair()    \n",
    "    output_words, decoder_attn = evaluate(pair[0])\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    \n",
    "    print('>', pair[0])\n",
    "    print('=', pair[1])\n",
    "    print('<', output_sentence)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected r_ [200], t [200] and src [232] to have the same number of elements, but got 200, 200 and 232 elements respectively at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:887",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-13c73f52e069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_randomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-84f798b528ae>\u001b[0m in \u001b[0;36mevaluate_randomly\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_randomly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rand_train_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0moutput_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-69af80277926>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence, max_length)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdecoder_attentions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdecoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdecoder_attention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Choose top word from output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchcuda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__iadd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__sub__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected r_ [200], t [200] and src [232] to have the same number of elements, but got 200, 200 and 232 elements respectively at /opt/conda/conda-bld/pytorch_1503970438496/work/torch/lib/TH/generic/THTensorMath.c:887"
     ]
    }
   ],
   "source": [
    "evaluate_randomly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
